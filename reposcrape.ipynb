{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12be58-40ec-43cd-84f6-02408a1249a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def get_repo_name(repo_url):\n",
    "    return repo_url.rstrip('/').split('/')[-1]\n",
    "\n",
    "def get_files(repo_url):\n",
    "    api_url = repo_url.replace(\"https://github.com/\", \"https://api.github.com/repos/\") + \"/contents\"\n",
    "    response = requests.get(api_url)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def download_file(file_url, save_path):\n",
    "    response = requests.get(file_url)\n",
    "    response.raise_for_status()\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "def is_plaintext_file(file_info):\n",
    "    plain_text_extensions = ('.txt', '.md', '.csv', '.log', '.json', '.yaml', '.yml', '.xml', '.ini', '.conf', '.html', '.rst')\n",
    "    plain_text_names = ('README', 'LICENSE', 'CONTRIBUTING', 'CHANGES', 'CHANGELOG')\n",
    "    \n",
    "    return (file_info['name'].endswith(plain_text_extensions) or\n",
    "            file_info['name'].split('.')[0] in plain_text_names or\n",
    "            file_info['name'].lower() in plain_text_names)\n",
    "\n",
    "def scrape_text_files(repo_url):\n",
    "    repo_name = get_repo_name(repo_url)\n",
    "    os.makedirs(repo_name, exist_ok=True)\n",
    "    try:\n",
    "        files = get_files(repo_url)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to fetch files from {repo_url}: {e}\")\n",
    "        return\n",
    "    \n",
    "    for file_info in files:\n",
    "        if file_info['type'] == 'file' and is_plaintext_file(file_info):\n",
    "            file_url = file_info['download_url']\n",
    "            save_path = os.path.join(repo_name, file_info['name'])\n",
    "            try:\n",
    "                download_file(file_url, save_path)\n",
    "                print(f\"Downloaded {file_info['name']} to {save_path}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Failed to download {file_info['name']} from {file_url}: {e}\")\n",
    "\n",
    "def scrape_repos_from_file(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"File {file_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        repo_urls = file.readlines()\n",
    "    \n",
    "    for repo_url in repo_urls:\n",
    "        repo_url = repo_url.strip()\n",
    "        if repo_url:\n",
    "            print(f\"Scraping repository: {repo_url}\")\n",
    "            scrape_text_files(repo_url)\n",
    "\n",
    "# Example usage\n",
    "file_path = \"repositories.txt\"  # Path to your text file containing repository URLs\n",
    "scrape_repos_from_file(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
